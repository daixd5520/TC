# 基础模型实验配置
model:
  base_model_path: "/mnt/data1/TC/TextClassDemo/llama3.1-8b"
  adapter_path: "/mnt/data1/TC/TextClassDemo/LLaMA-Factory/llama3.1-8b_ohsumed_direct_lora_english_prompt"
  use_lora: false

data:
  data_path: "/mnt/data1/TC/TextClassDemo/data/ohsumed/ohsumed_Test_alpaca_noCoT_updated.json"
  dataset_name: ohsumed
  num_classes: 23

generation:
  max_new_tokens: 256
  temperature: 1.0
  top_p: 0.9
  do_sample: true

training:
  batch_size: 512
  vote_count: 10

output:
  base_output_dir: "./outputs"
  experiment_name: "ohsumed_base_zeroshotCoT_vote5"